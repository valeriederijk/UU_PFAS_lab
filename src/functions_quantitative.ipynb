{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8d6f1d5-c425-400c-a3cc-799e42f6de29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import csv\n",
    "import seaborn as sns\n",
    "def detect_csv_delimiter(csv_path):\n",
    "    \"\"\"\n",
    "    Detect the delimiter used in a CSV file by checking the first line.\n",
    "    Returns the delimiter that appears more frequently.\n",
    "    \"\"\"\n",
    "    with open(csv_path, 'r', encoding='utf-8') as f:\n",
    "        first_line = f.readline().strip()\n",
    "    \n",
    "    semicolon_count = first_line.count(';')\n",
    "    comma_count = first_line.count(',')\n",
    "    \n",
    "    # Return the delimiter that appears more frequently\n",
    "    if semicolon_count > comma_count:\n",
    "        return ';'\n",
    "    elif comma_count > semicolon_count:\n",
    "        return ','\n",
    "    else:\n",
    "        # If counts are equal, default to semicolon (original behavior)\n",
    "        # You could also raise an exception here if preferred\n",
    "        return ';'\n",
    "\n",
    "def load_and_label_pfas_csv(csv_path):\n",
    "    \"\"\"\n",
    "    Load a PFAS CSV file, combine headers, and return a labeled DataFrame.\n",
    "    Automatically detects whether the file uses semicolon (;) or comma (,) delimiters.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    csv_path : str\n",
    "        Path to the raw CSV file.\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with combined headers for PFAS compounds.\n",
    "    \"\"\"\n",
    "    # Detect the delimiter\n",
    "    delimiter = detect_csv_delimiter(csv_path)\n",
    "    print(f\"Detected delimiter: '{delimiter}'\")\n",
    "    \n",
    "    # Read the first two lines to construct headers\n",
    "    with open(csv_path, 'r', encoding='utf-8') as f:\n",
    "        first_line = f.readline().strip().split(delimiter)\n",
    "        second_line = f.readline().strip().split(delimiter)\n",
    "    \n",
    "    # Extract PFAS compound names from the first line (skip 'Sample')\n",
    "    # Keep track of which compounds are ISTDs\n",
    "    pfas_compounds = []\n",
    "    is_istd = []\n",
    "    \n",
    "    for name in first_line[1:]:\n",
    "        if 'Results' in name:\n",
    "            # Check if this is an ISTD\n",
    "            is_istd_compound = '(ISTD)' in name\n",
    "            is_istd.append(is_istd_compound)\n",
    "            \n",
    "            # Clean the name\n",
    "            clean_name = name.replace(' Results', '').replace(' (ISTD)', '')\n",
    "            pfas_compounds.append(clean_name)\n",
    "    \n",
    "    print(pfas_compounds)\n",
    "    \n",
    "    # Define isotope prefixes to exclude\n",
    "    isotope_prefixes = (\"13C\", \"D3-\", \"D5-\", \"D7-\", \"D9-\", \"18O\")\n",
    "    \n",
    "    # Example: if pfas_compounds is a list of compound names\n",
    "    native_compounds = [c for c in pfas_compounds if not c.startswith(isotope_prefixes)]\n",
    "    \n",
    "    print(f\"Total compounds: {len(pfas_compounds)}\")\n",
    "    print(f\"Without isotope prefix: {len(native_compounds)}\")\n",
    "    \n",
    "    # Create combined headers\n",
    "    combined_headers = []\n",
    "    pfas_index = 0\n",
    "    \n",
    "    # Define metadata columns\n",
    "    metadata_cols = ['Name', 'Data File', 'Type', 'Level', 'Acq. Date-Time']\n",
    "    \n",
    "    # Define possible PFAS columns\n",
    "    pfas_data_cols = ['RT', 'Final Conc.', 'Calc. Conc.', 'Surrogate % Recovery',\n",
    "                      'Accuracy', 'ISTD Conc. Ratio', 'Area', 'Resp.', 'RR', 'S/N']\n",
    "    \n",
    "    for header in second_line:\n",
    "        # Keep initial metadata columns as they are\n",
    "        if header in metadata_cols:\n",
    "            combined_headers.append(header)\n",
    "        # For PFAS-related columns\n",
    "        elif header in pfas_data_cols:\n",
    "            if pfas_index < len(pfas_compounds):\n",
    "                combined_headers.append(f\"{pfas_compounds[pfas_index]}_{header}\")\n",
    "                \n",
    "                # Determine the last column based on whether this is an ISTD\n",
    "                if is_istd[pfas_index]:\n",
    "                    # ISTD compounds end with Resp.\n",
    "                    if header == 'Resp.':\n",
    "                        pfas_index += 1\n",
    "                else:\n",
    "                    # Non-ISTD compounds end with S/N\n",
    "                    if header == 'S/N':\n",
    "                        pfas_index += 1\n",
    "            else:\n",
    "                combined_headers.append(header)\n",
    "        else:\n",
    "            combined_headers.append(header)\n",
    "    \n",
    "    # Read the actual data (skip first 2 lines) using the detected delimiter\n",
    "    rawdata = pd.read_csv(csv_path, delimiter=delimiter, skiprows=2, header=None)\n",
    "    \n",
    "    # Assign the combined headers (handle extra/fewer columns)\n",
    "    if len(combined_headers) <= len(rawdata.columns):\n",
    "        rawdata.columns = combined_headers + [f\"Extra_Col_{i}\" for i in range(len(combined_headers), len(rawdata.columns))]\n",
    "    else:\n",
    "        rawdata.columns = combined_headers[:len(rawdata.columns)]\n",
    "    \n",
    "    return rawdata\n",
    "\n",
    "def check_calibration_sn_ratios(rawdata):\n",
    "    \"\"\"\n",
    "    Check if all compounds in calibration samples have S/N ratios above 3\n",
    "    \n",
    "    Parameters:\n",
    "    rawdata: DataFrame with PFAS data containing Type column and S/N ratio columns\n",
    "    \n",
    "    Returns:\n",
    "    dict: Summary of S/N ratio check results\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter for calibration samples\n",
    "    cal_samples = rawdata[rawdata['Type'] == 'Cal'].copy()\n",
    "    \n",
    "    if cal_samples.empty:\n",
    "        return {\"error\": \"No calibration samples found in the data\"}\n",
    "    \n",
    "    # Find all S/N ratio columns (assuming format: compoundname_S/N)\n",
    "    sn_columns = [col for col in rawdata.columns if col.endswith('_S/N')]\n",
    "    \n",
    "    if not sn_columns:\n",
    "        return {\"error\": \"No S/N ratio columns found\"}\n",
    "    \n",
    "    print(f\"Found {len(sn_columns)} S/N ratio columns for compounds:\")\n",
    "    for col in sn_columns[:5]:  # Show first 5\n",
    "        print(f\"  - {col}\")\n",
    "    if len(sn_columns) > 5:\n",
    "        print(f\"  ... and {len(sn_columns) - 5} more\")\n",
    "    \n",
    "    results = {\n",
    "        'total_compounds': len(sn_columns),\n",
    "        'total_cal_samples': len(cal_samples),\n",
    "        'compounds_failing_sn3': [],\n",
    "        'compounds_passing_sn3': [],\n",
    "        'summary_stats': {}\n",
    "    }\n",
    "    \n",
    "    # Check each compound's S/N ratios in calibration samples\n",
    "    for sn_col in sn_columns:\n",
    "        compound_name = sn_col.replace('_S/N', '')\n",
    "        \n",
    "        # Get S/N values for this compound in cal samples\n",
    "        sn_values = cal_samples[sn_col]\n",
    "        \n",
    "        # Remove NaN values\n",
    "        valid_sn_values = sn_values.dropna()\n",
    "        \n",
    "        if len(valid_sn_values) == 0:\n",
    "            results['compounds_failing_sn3'].append({\n",
    "                'compound': compound_name,\n",
    "                'issue': 'No valid S/N values found',\n",
    "                'min_sn': None,\n",
    "                'samples_below_3': None\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # Check if all values are above 3\n",
    "        min_sn = valid_sn_values.min()\n",
    "        samples_below_3 = (valid_sn_values < 3).sum()\n",
    "        \n",
    "        results['summary_stats'][compound_name] = {\n",
    "            'min_sn': min_sn,\n",
    "            'mean_sn': valid_sn_values.mean(),\n",
    "            'samples_below_3': samples_below_3,\n",
    "            'total_samples': len(valid_sn_values)\n",
    "        }\n",
    "        \n",
    "        if min_sn < 3:\n",
    "            results['compounds_failing_sn3'].append({\n",
    "                'compound': compound_name,\n",
    "                'min_sn': min_sn,\n",
    "                'samples_below_3': samples_below_3,\n",
    "                'total_samples': len(valid_sn_values)\n",
    "            })\n",
    "        else:\n",
    "            results['compounds_passing_sn3'].append(compound_name)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def print_sn_check_results(results):\n",
    "    \"\"\"Print formatted results of S/N ratio check\"\"\"\n",
    "    \n",
    "    if 'error' in results:\n",
    "        print(f\"Error: {results['error']}\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PFAS CALIBRATION S/N RATIO CHECK RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"Total compounds analyzed: {results['total_compounds']}\")\n",
    "    print(f\"Total calibration samples: {results['total_cal_samples']}\")\n",
    "    \n",
    "    passing_count = len(results['compounds_passing_sn3'])\n",
    "    failing_count = len(results['compounds_failing_sn3'])\n",
    "    \n",
    "    print(f\"\\nCompounds with ALL S/N ratios ≥ 3: {passing_count}\")\n",
    "    print(f\"Compounds with ANY S/N ratios < 3: {failing_count}\")\n",
    "    \n",
    "    if failing_count == 0:\n",
    "        print(\"\\n✅ SUCCESS: All compounds in calibration samples have S/N ratios ≥ 3\")\n",
    "    else:\n",
    "        print(f\"\\n❌ ISSUE: {failing_count} compounds have S/N ratios < 3 in calibration samples\")\n",
    "        \n",
    "        print(\"\\nCompounds failing S/N ≥ 3 criterion:\")\n",
    "        print(\"-\" * 40)\n",
    "        for fail in results['compounds_failing_sn3']:\n",
    "            if fail.get('issue'):\n",
    "                print(f\"  {fail['compound']}: {fail['issue']}\")\n",
    "            else:\n",
    "                print(f\"  {fail['compound']}: Min S/N = {fail['min_sn']:.2f}, \"\n",
    "                      f\"{fail['samples_below_3']}/{fail['total_samples']} samples < 3\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "    \n",
    "def calculate_rse(expected, measured, compound_name, p=2):\n",
    "    if len(expected) != len(measured):\n",
    "        raise ValueError(\"Expected and measured arrays must have the same length\")\n",
    "\n",
    "    def compute_rse(expected, measured, p, compound_name):\n",
    "        n = len(expected)\n",
    "        sum_relative_squared_error = 0\n",
    "        detailed_results = []\n",
    "\n",
    "        print(f\"\\n{compound_name} (p={p})\")\n",
    "        print(\"=\" * 60)\n",
    "        print(\"Point\\tExpected\\tMeasured\\tDifference\\t(Diff)²/xi²\\t(Diff)²/xi²/(n-p)\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "        for i in range(n):\n",
    "            diff = measured[i] - expected[i]\n",
    "            nominator = (diff / expected[i]) ** 2\n",
    "            relative_squared_error = nominator / (n - p)\n",
    "            sum_relative_squared_error += relative_squared_error\n",
    "\n",
    "            detailed_results.append({\n",
    "                'Point': f'CAL {i+1}',\n",
    "                'Expected': expected[i],\n",
    "                'Measured': measured[i],\n",
    "                'Difference': diff,\n",
    "                'Nominator': nominator,\n",
    "                'Relative_Squared_Error_Term': relative_squared_error\n",
    "            })\n",
    "\n",
    "            print(f\"CAL {i+1}\\t{expected[i]}\\t\\t{measured[i]:.4f}\\t\\t{diff:.4f}\\t\\t\"\n",
    "                  f\"{nominator:.6f}\\t{relative_squared_error:.6f}\")\n",
    "\n",
    "        rse = 100 * math.sqrt(sum_relative_squared_error)\n",
    "\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"Sum of relative squared errors: {sum_relative_squared_error:.6f}\")\n",
    "        print(f\"RSE = 100 * √({sum_relative_squared_error:.6f}) = {rse:.3f}%\")\n",
    "\n",
    "        return rse, detailed_results, sum_relative_squared_error\n",
    "\n",
    "    rse, details, sum_rse = compute_rse(expected, measured, p, compound_name)\n",
    "    relationship_type = \"linear\" if p == 2 else \"quadratic\"\n",
    "\n",
    "    if p == 2 and rse > 20:\n",
    "        print(\"\\nLinearity test failed (RSE > 20%), recalculating with p=3 (quadratic)...\")\n",
    "        p = 3\n",
    "        rse, details, sum_rse = compute_rse(expected, measured, p, compound_name)\n",
    "        relationship_type = \"quadratic\"\n",
    "\n",
    "    return {\n",
    "        'compound_name': compound_name,\n",
    "        'n_points': len(expected),\n",
    "        'parameters': p,\n",
    "        'relationship_type': relationship_type,\n",
    "        'rse_percent': rse,\n",
    "        'sum_relative_squared_error': sum_rse,\n",
    "        'detailed_results': details\n",
    "    }\n",
    "\n",
    "def calculate_target_rse(df, expected_concentrations, p=2, level_to_exclude=None):\n",
    "    target_analytes = []\n",
    "    for col in df.columns:\n",
    "        if '_Conc_Calc' in col:\n",
    "            compound_name = col.replace('_Conc_Calc', '')\n",
    "            if compound_name in expected_concentrations:\n",
    "                target_analytes.append(compound_name)\n",
    "    \n",
    "    print(f\"Identified target analytes: {target_analytes}\")\n",
    "    print(f\"Number of identified target analytes: {len(target_analytes)}\")\n",
    "    \n",
    "    cal_data = df[df['Type'] == 'Cal'].copy()\n",
    "    if cal_data.empty:\n",
    "        print(\"No CAL samples found in the data\")\n",
    "        return {}, pd.DataFrame()\n",
    "    \n",
    "    rse_results_target = {}\n",
    "    rse_results_excluded = {}\n",
    "    \n",
    "    for compound in target_analytes:\n",
    "        conc_col = f\"{compound}_Conc_Calc\"\n",
    "        if conc_col not in df.columns or compound not in expected_concentrations:\n",
    "            continue\n",
    "        \n",
    "        actual_concs = cal_data[conc_col].values\n",
    "        expected_list = np.array(expected_concentrations[compound], dtype=float)\n",
    "        level_list = cal_data[\"Level\"].values\n",
    "        \n",
    "        # --- Handle special compounds (exclude 7th point) ---\n",
    "        special_compounds = ['4:2FTS', '6:2FTS', '8:2FTS']\n",
    "        if compound in special_compounds:\n",
    "            if len(actual_concs) > 6:\n",
    "                actual_concs = actual_concs[:6]\n",
    "                expected_list = expected_list[:6]\n",
    "                level_list = level_list[:6]\n",
    "                print(f\"Using only first 6 calibration points for {compound}\")\n",
    "        \n",
    "        # --- Normal RSE ---\n",
    "        valid_mask = ~np.isnan(actual_concs)\n",
    "        actual_clean = actual_concs[valid_mask]\n",
    "        expected_clean = expected_list[valid_mask]\n",
    "        \n",
    "        if len(actual_clean) == 0:\n",
    "            continue\n",
    "        \n",
    "        rse_normal = calculate_rse(expected_clean.tolist(), actual_clean.tolist(), compound, p)\n",
    "        rse_results_target[compound] = rse_normal\n",
    "        \n",
    "        # --- Exclude calibration level (e.g., Level == 3) ---\n",
    "        mask_excl = (level_list != level_to_exclude) & valid_mask\n",
    "        actual_excl = actual_concs[mask_excl]\n",
    "        expected_excl = expected_list[mask_excl]\n",
    "        \n",
    "        if len(actual_excl) > 0:\n",
    "            rse_excl = calculate_rse(expected_excl.tolist(), actual_excl.tolist(), compound, p)\n",
    "            rse_results_excluded[compound] = rse_excl\n",
    "    \n",
    "\n",
    "    \n",
    "    return rse_results_target, rse_results_excluded\n",
    "\n",
    "\n",
    "\n",
    "def print_rse_summary(rse_results):\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"COMPOUND RSE SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    # First output: List of compounds that fail the linearity test (RSE > 20%)\n",
    "    failed_compounds = []\n",
    "    for compound, results in rse_results.items():\n",
    "        if results['rse_percent'] > 20:\n",
    "            failed_compounds.append(compound)\n",
    "    \n",
    "    print(\"Compounds that do not pass the linearity test (RSE > 20%):\")\n",
    "    for compound in failed_compounds:\n",
    "        print(f\"  - {compound}\")\n",
    "    \n",
    "    print(\"\\ndetailed output below\")\n",
    "\n",
    "    for compound, results in rse_results.items():\n",
    "        print(f\"\\n{compound}:\")\n",
    "        print(f\"  RSE: {results['rse_percent']:.3f}%\")\n",
    "        print(f\"  Calibration Points: {results['n_points']}\")\n",
    "        print(f\"  Relationship type: {results['relationship_type']} (p = {results['parameters']})\")\n",
    "\n",
    "        if results['relationship_type'] == \"quadratic\" and results['rse_percent'] > 20:\n",
    "            print(\"  ⚠ WARNING: Even after quadratic fit (p=3), RSE > 20% — system fails.\")\n",
    "        elif results['relationship_type'] == \"quadratic\":\n",
    "            print(\"  ✔ Quadratic fit passed RSE < 20%.\")\n",
    "        elif results['rse_percent'] > 20:\n",
    "            print(\"  ⚠ Linear fit failed RSE > 20%.\")\n",
    "\n",
    "def df_rse_results(rse_results):\n",
    "    \"\"\"\n",
    "    Save RSE results to a CSV file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rse_results : dict\n",
    "        Dictionary containing RSE results for each compound\n",
    "    filename : str\n",
    "        Name of the output CSV file\n",
    "    \"\"\"\n",
    "    # Prepare data for CSV\n",
    "    csv_data = []\n",
    "    \n",
    "    for compound, results in rse_results.items():\n",
    "        # Determine pass/fail status\n",
    "        pass_fail = \"FAIL\" if results['rse_percent'] > 20 else \"PASS\"\n",
    "        \n",
    "        csv_data.append({\n",
    "            'Compound': compound,\n",
    "            'RSE_Percent': results['rse_percent'],\n",
    "            'Calibration_Points': results['n_points'],\n",
    "            'Relationship_Type': results['relationship_type'],\n",
    "            'Parameters': results['parameters'],\n",
    "            'Pass_Fail': pass_fail,\n",
    "            'Sum_Relative_Squared_Error': results['sum_relative_squared_error']\n",
    "        })\n",
    "    \n",
    "    # Create DataFrame and save to CSV\n",
    "    df = pd.DataFrame(csv_data)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_average_RFs_EIS(rawdata, EIS_NIS_analogs, calibration_solutions):\n",
    "    \"\"\"\n",
    "    Calculate average response factors for EIS compounds across calibration levels.\n",
    "    \n",
    "    Parameters:\n",
    "    rawdata: DataFrame containing the analytical data\n",
    "    EIS_NIS_analogs: Dictionary mapping EIS compounds to their corresponding NIS\n",
    "    calibration_solutions: Dictionary containing mass data for L1-L7 calibration levels\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame with compound name, mass NIS, mass EIS, RR values, and average response factor\n",
    "    \"\"\"\n",
    "    \n",
    "    # Identify relevant columns (Area and RR) that match EIS_NIS_analogs\n",
    "    relevant_columns = []\n",
    "    for col in rawdata.columns:\n",
    "        if ('Area' in col or 'RR' in col):\n",
    "            # Extract compound name from column (assuming format like \"CompoundName_Area\" or \"CompoundName_RR\")\n",
    "            compound_name = col.replace('_Area', '').replace('_RR', '')\n",
    "            if compound_name in EIS_NIS_analogs:\n",
    "                relevant_columns.append(col)\n",
    "    \n",
    "    # Filter dataframe for CAL sample type\n",
    "    cal_data = rawdata[rawdata['Type'] == 'Cal'].copy()\n",
    "    \n",
    "    # Initialize results list\n",
    "    results = []\n",
    "    \n",
    "    # Get unique EIS compounds from the relevant columns\n",
    "    eis_compounds = set()\n",
    "    for col in relevant_columns:\n",
    "        if '_RR' in col:  # We need RR columns for calculation\n",
    "            compound_name = col.replace('_RR', '')\n",
    "            if compound_name in EIS_NIS_analogs:\n",
    "                eis_compounds.add(compound_name)\n",
    "    \n",
    "    # Process each EIS compound\n",
    "    for eis_compound in eis_compounds:\n",
    "        # Get corresponding NIS compound\n",
    "        nis_compound = EIS_NIS_analogs[eis_compound]\n",
    "        \n",
    "        # Get RR column for this compound\n",
    "        rr_column = f\"{eis_compound}_RR\"\n",
    "        \n",
    "        if rr_column not in cal_data.columns:\n",
    "            print(f\"Warning: RR column {rr_column} not found in data\")\n",
    "            continue\n",
    "        \n",
    "        # Calculate response factors for each calibration level\n",
    "        response_factors = []\n",
    "        level_data = []\n",
    "        \n",
    "        for level in ['L1', 'L2', 'L3', 'L4', 'L5', 'L6', 'L7']:\n",
    "            # Get calibration level data\n",
    "            level_cal_data = cal_data[cal_data['Level'] == level]\n",
    "            \n",
    "            if level_cal_data.empty:\n",
    "                print(f\"Warning: No data found for level {level}\")\n",
    "                continue\n",
    "            \n",
    "            # Get masses from calibration_solutions\n",
    "            # Check if compounds exist in calibration_solutions\n",
    "            if nis_compound not in calibration_solutions:\n",
    "                print(f\"Warning: NIS compound {nis_compound} not found in calibration_solutions\")\n",
    "                continue\n",
    "            if eis_compound not in calibration_solutions:\n",
    "                print(f\"Warning: EIS compound {eis_compound} not found in calibration_solutions\")\n",
    "                continue\n",
    "            \n",
    "            # Get mass of NIS and EIS for this level\n",
    "            mass_nis = calibration_solutions[nis_compound].get(level, np.nan)\n",
    "            mass_eis = calibration_solutions[eis_compound].get(level, np.nan)\n",
    "            \n",
    "            if pd.isna(mass_nis) or pd.isna(mass_eis):\n",
    "                print(f\"Warning: Missing mass data for {eis_compound} or {nis_compound} at level {level}\")\n",
    "                continue\n",
    "            \n",
    "            # Get RR value for this level (assuming one value per level)\n",
    "            rr_values = level_cal_data[rr_column].dropna()\n",
    "            \n",
    "            if rr_values.empty:\n",
    "                print(f\"Warning: No RR values found for {eis_compound} at level {level}\")\n",
    "                continue\n",
    "            \n",
    "            # Use the first (or mean if multiple) RR value for this level\n",
    "            compound_rr = rr_values.iloc[0] if len(rr_values) == 1 else rr_values.mean()\n",
    "            \n",
    "            # Calculate response factor: compound_RR * (mass_NIS / mass_EIS)\n",
    "            if mass_eis != 0:\n",
    "                response_factor = compound_rr * (mass_nis / mass_eis)\n",
    "                response_factors.append(response_factor)\n",
    "                \n",
    "                level_data.append({\n",
    "                    'Level': level,\n",
    "                    'Compound_RR': compound_rr,\n",
    "                    'Mass_NIS': mass_nis,\n",
    "                    'Mass_EIS': mass_eis,\n",
    "                    'Response_Factor': response_factor\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Warning: Mass EIS is zero for {eis_compound} at level {level}\")\n",
    "        \n",
    "        # Calculate average response factor\n",
    "        if response_factors:\n",
    "            avg_response_factor = np.mean(response_factors)\n",
    "            \n",
    "            # Get representative masses (from L4 or first available level)\n",
    "            rep_level = 'L4'\n",
    "            if nis_compound in calibration_solutions and rep_level in calibration_solutions[nis_compound]:\n",
    "                rep_mass_nis = calibration_solutions[nis_compound][rep_level]\n",
    "            else:\n",
    "                rep_mass_nis = np.nan\n",
    "                \n",
    "            if eis_compound in calibration_solutions and rep_level in calibration_solutions[eis_compound]:\n",
    "                rep_mass_eis = calibration_solutions[eis_compound][rep_level]\n",
    "            else:\n",
    "                rep_mass_eis = np.nan\n",
    "            \n",
    "            results.append({\n",
    "                'Compound_Name': eis_compound,\n",
    "                'NIS_Analog': nis_compound,\n",
    "                'Mass_NIS': rep_mass_nis,\n",
    "                'Mass_EIS': rep_mass_eis,\n",
    "                'RR_Values': [ld['Compound_RR'] for ld in level_data],\n",
    "                'Response_Factors': response_factors,\n",
    "                'Average_Response_Factor': avg_response_factor,\n",
    "                'N_Levels': len(response_factors)\n",
    "            })\n",
    "        else:\n",
    "            print(f\"Warning: No valid response factors calculated for {eis_compound}\")\n",
    "    \n",
    "    # Create output DataFrame\n",
    "    if results:\n",
    "    # Create DataFrame\n",
    "        output_df = pd.DataFrame([\n",
    "            {\n",
    "                'Compound_Name': r['Compound_Name'],\n",
    "                'NIS_Analog': r['NIS_Analog'],\n",
    "                'Mass_NIS': r['Mass_NIS'],\n",
    "                'Mass_EIS': r['Mass_EIS'],\n",
    "                'Average_Response_Factor': r['Average_Response_Factor'],\n",
    "                'RSD_%': (np.std(r['Response_Factors']) / np.mean(r['Response_Factors']) * 100)\n",
    "                        if len(r['Response_Factors']) > 1 else np.nan\n",
    "            }\n",
    "            for r in results\n",
    "        ])\n",
    "    \n",
    "        # Round numerical columns\n",
    "        output_df['Mass_NIS'] = output_df['Mass_NIS'].round(3)\n",
    "        output_df['Mass_EIS'] = output_df['Mass_EIS'].round(3)\n",
    "        output_df['Average_Response_Factor'] = output_df['Average_Response_Factor'].round(4)\n",
    "        output_df['RSD_%'] = output_df['RSD_%'].round(2)\n",
    "    \n",
    "        # Display clean table in Jupyter\n",
    "        print(f\"\\nAVERAGE RESPONSE FACTORS FOR EIS COMPOUNDS (n={len(output_df)})\")\n",
    "        display(output_df)\n",
    "        \n",
    "        return output_df\n",
    "    else:\n",
    "        print(\"No valid results calculated\")\n",
    "        return pd.DataFrame()\n",
    "        print(\"No valid results calculated\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def calc_mass_added_NIS(NIS_stock, dilution_NIS_stock, spiked_amount):\n",
    "    \"\"\"\n",
    "    Calculate mass of NIS added for each compound.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    NIS_stock : dict\n",
    "        Stock concentrations of NIS (ng/mL)\n",
    "    dilution_NIS_stock : float\n",
    "        Dilution factor (e.g., 10 for 1:10 dilution)\n",
    "    spiked_amount : float\n",
    "        Volume spiked [L]\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Mass of each NIS compound added [ng]\n",
    "    \"\"\"\n",
    "    NIS_added_dict = {}\n",
    "\n",
    "    for compound, stock_conc in NIS_stock.items():\n",
    "        # Convert spiked volume (L) → mL to match ng/mL units\n",
    "        NIS_added = (stock_conc / dilution_NIS_stock) * (spiked_amount)\n",
    "        NIS_added_dict[compound] = NIS_added\n",
    "\n",
    "    return NIS_added_dict\n",
    "\n",
    "def calc_mass_added_EIS(EIS_stock, dilution_EIS_stock, spiked_amount):\n",
    "    \"\"\"\n",
    "    Calculate spiked concentration of EIS in ng/L.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    EIS_stock : dict\n",
    "        Stock concentrations of EIS (ng/mL).\n",
    "    dilution_EIS_stock : float\n",
    "        Dilution factor (e.g., 10 for 1:10 dilution).\n",
    "    spiked_amount : float\n",
    "        Volume spiked [mL].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Spiked concentration of each EIS compound [ng/L].\n",
    "    \"\"\"\n",
    "    EIS_added_dict = {}\n",
    "\n",
    "    for compound, stock_conc in EIS_stock.items():\n",
    "        # Amount added (ng) = (conc in ng/mL / dilution) * spiked volume (mL)\n",
    "        EIS_added_ng = (stock_conc / dilution_EIS_stock) * spiked_amount  \n",
    "        # Convert to concentration in ng/L by dividing by sample volume\n",
    "        EIS_spiked_conc = EIS_added_ng\n",
    "        EIS_added_dict[compound] = EIS_spiked_conc\n",
    "\n",
    "    return EIS_added_dict\n",
    "\n",
    "        \n",
    "\n",
    "def calculate_conc_EIS(rawdata, EIS_RFS, dilution_NIS_stock, EIS_NIS_analogs,\n",
    "                       Df, NIS_stock, spiked_amount):\n",
    "    \"\"\"\n",
    "    Calculate concentrations for EIS compounds in sample data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rawdata : DataFrame\n",
    "        Input data with RR values, sample info, and Ws (sample weights) column.\n",
    "    EIS_RFS : DataFrame\n",
    "        Contains Average_Response_Factor per compound.\n",
    "    dilution_NIS_stock : float\n",
    "        Dilution factor for NIS stock.\n",
    "    EIS_NIS_analogs : dict\n",
    "        Mapping from EIS compound -> NIS analog.\n",
    "    Df : float\n",
    "        Dilution factor for samples.\n",
    "    NIS_stock : dict\n",
    "        NIS stock concentrations (ng/mL).\n",
    "    spiked_amount : float\n",
    "        Volume spiked [L].\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (conc_data, nis_masses_df)\n",
    "        - conc_data: DataFrame with Name, Type, and calculated concentration columns\n",
    "        - nis_masses_df: DataFrame with NIS compound names and their added masses\n",
    "    \"\"\"\n",
    "    # Compute the amount of added NIS per NIS compound \n",
    "    NIS_added = calc_mass_added_NIS(NIS_stock, dilution_NIS_stock, spiked_amount)\n",
    "    \n",
    "    # Create NIS masses DataFrame\n",
    "    nis_masses_df = pd.DataFrame([\n",
    "        {'NIS_Compound': compound, 'Mass_Added_ng': mass}\n",
    "        for compound, mass in NIS_added.items()\n",
    "    ])\n",
    "    \n",
    "    # Only look at samples (not calibration lines)\n",
    "    sample_data = rawdata[rawdata['Type'] == 'Sample'].copy()\n",
    "    \n",
    "    # Check for Ws column\n",
    "    if 'Ws' not in sample_data.columns:\n",
    "        print(\"Error: 'Ws' column not found in rawdata\")\n",
    "        return None, nis_masses_df\n",
    "    \n",
    "    # Identify samples without Ws values\n",
    "    missing_ws_mask = sample_data['Ws'].isna()\n",
    "    samples_without_ws = sample_data[missing_ws_mask]['Name'].tolist()\n",
    "    \n",
    "    if samples_without_ws:\n",
    "        print(f\"Warning: The following samples do not have Ws values and will be skipped:\")\n",
    "        for sample in samples_without_ws:\n",
    "            print(f\"  - {sample}\")\n",
    "    \n",
    "    # Filter to only samples with Ws values\n",
    "    sample_data_with_ws = sample_data[~missing_ws_mask].copy()\n",
    "    \n",
    "    if sample_data_with_ws.empty:\n",
    "        print(\"Error: No samples have Ws values\")\n",
    "        return None, nis_masses_df\n",
    "    \n",
    "    # Start output DataFrame with identifiers\n",
    "    conc_data = sample_data_with_ws[['Name', 'Type', 'Ws']].copy()\n",
    "    \n",
    "    # Get unique EIS compounds from analog mapping\n",
    "    eis_compounds = set(EIS_NIS_analogs.keys())\n",
    "    \n",
    "    # Process each EIS compound\n",
    "    for eis_compound in eis_compounds:\n",
    "        nis_compound = EIS_NIS_analogs[eis_compound]\n",
    "        rr_column = f\"{eis_compound}_RR\"\n",
    "        \n",
    "        if rr_column not in sample_data_with_ws.columns:\n",
    "            print(f\"Warning: RR column {rr_column} not found in data\")\n",
    "            continue\n",
    "        \n",
    "        # Get average RF for this compound\n",
    "        avg_rf_row = EIS_RFS[EIS_RFS[\"Compound_Name\"] == eis_compound]\n",
    "        if avg_rf_row.empty:\n",
    "            print(f\"Warning: No RF found for {eis_compound}\")\n",
    "            continue\n",
    "        avg_rf = avg_rf_row[\"Average_Response_Factor\"].values[0]\n",
    "        \n",
    "        # Get mass of NIS analog added\n",
    "        if nis_compound not in NIS_added:\n",
    "            print(f\"Warning: No NIS mass found for analog {nis_compound}\")\n",
    "            continue\n",
    "        m_nis = NIS_added[nis_compound]\n",
    "        \n",
    "        # Compute concentrations using individual Ws values\n",
    "        conc_values = (sample_data_with_ws[rr_column] * m_nis / avg_rf) * Df * (1 / sample_data_with_ws['Ws'])\n",
    "        conc_data[f\"{eis_compound}_Conc_Calc\"] = conc_values\n",
    "    \n",
    "    print(f\"\\nCalculated concentrations for {len(conc_data)} samples with Ws values\")\n",
    "    print(f\"\\nNIS masses added per compound:\")\n",
    "    display(nis_masses_df)\n",
    "    print(f\"\\nConcentration results:\")\n",
    "    display(conc_data)\n",
    "    \n",
    "    return conc_data, nis_masses_df\n",
    "\n",
    "\n",
    "def calculate_recoveries(conc_data, expected_concs):\n",
    "    \"\"\"\n",
    "    Calculate recovery for eachcompound.\n",
    "    Recovery = (Calculated concentration / Expected concentration) * 100\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    conc_data : DataFrame\n",
    "        Output from calculate_conc containing *_Conc_Calc columns.\n",
    "    expected_concs_EIS : dict\n",
    "        Expected concentrations of compounds (ng/L).\n",
    "    Ws : float\n",
    "        Sample volume [L].\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        Recovery (%) for each compound per sample.\n",
    "    \"\"\"\n",
    "    # Start recovery DataFrame with identifiers\n",
    "    recovery_data = conc_data[['Name', 'Type']].copy()\n",
    "    \n",
    "    # Loop over compounds in expected concentrations dictionary\n",
    "    for eis_compound, expected_conc in expected_concs.items():\n",
    "        calc_col = f\"{eis_compound}_Conc_Calc\"\n",
    "        \n",
    "        if calc_col not in conc_data.columns:\n",
    "            print(f\"Warning: {calc_col} not found in calculated concentrations.\")\n",
    "            continue\n",
    "        \n",
    "        # Use the expected concentration directly from the dictionary\n",
    "        recovery_data[f\"{eis_compound}_Recovery_%\"] = (\n",
    "            (conc_data[calc_col] / expected_conc) * 100\n",
    "        )\n",
    "    \n",
    "    display(recovery_data)\n",
    "    return recovery_data\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_calculated_vs_expected(conc_data, expected_concs, analyte):\n",
    "    \"\"\"\n",
    "    Plot calculated vs expected concentrations for a given analyte, \n",
    "    with a linear regression fit and 1:1 line.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    conc_data : pd.DataFrame\n",
    "        DataFrame with calculated concentrations. Must include \n",
    "        columns like \"{analyte}_Conc_Calc\".\n",
    "    expected_concs : dict\n",
    "        Dictionary of expected concentrations, e.g. {\"PFOS\": 100, \"PFOA\": 200, ...}\n",
    "    analyte : str\n",
    "        Target analyte to plot (must match keys in expected_concs).\n",
    "    \"\"\"\n",
    "    calc_col = f\"{analyte}_Conc_Calc\"\n",
    "    if calc_col not in conc_data.columns:\n",
    "        raise ValueError(f\"{calc_col} not found in conc_data\")\n",
    "    \n",
    "    # Expected concentration is constant per analyte from dict\n",
    "    x = np.full_like(conc_data[calc_col].values, expected_concs[analyte], dtype=float).reshape(-1, 1)\n",
    "    y = conc_data[calc_col].values\n",
    "\n",
    "    # Linear regression\n",
    "    model = LinearRegression().fit(x, y)\n",
    "    y_pred = model.predict(x)\n",
    "    r2 = model.score(x, y)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.scatterplot(x=x.flatten(), y=y, s=60, edgecolor=\"k\", alpha=0.8)\n",
    "    plt.plot(x, y_pred, \"--\", color=\"#FDBE85\", lw=2,\n",
    "             label=f\"Fit: y = {model.coef_[0]:.2f}x + {model.intercept_:.2f}\\n$R^2$ = {r2:.3f}\")\n",
    "    \n",
    "    # 1:1 line\n",
    "    lims = [min(x.min(), y.min()), max(x.max(), y.max())]\n",
    "    plt.plot(lims, lims, \"--\", color=\"gray\", label=\"1:1 line\")\n",
    "    \n",
    "    plt.xlabel(\"Expected Concentration\")\n",
    "    plt.ylabel(\"Calculated Concentration\")\n",
    "    plt.title(f\"{analyte}: Calculated vs Expected\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def validate_recoveries(calculated_recoveries_df, expected_recoveries_df):\n",
    "    \"\"\"\n",
    "    Compare calculated recoveries against expected recovery ranges.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    calculated_recoveries_df : pd.DataFrame\n",
    "        DataFrame containing calculated recoveries with recovery columns named like 'compound_Recovery_%'\n",
    "    expected_recoveries_df : pd.DataFrame\n",
    "        DataFrame with columns: 'compound', 'compound_type', 'lower_recovery_percent', 'upper_recovery_percent'\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Validation results with pass/fail status for each compound and sample\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a mapping from expected recoveries for quick lookup\n",
    "    recovery_ranges = {}\n",
    "    for _, row in expected_recoveries_df.iterrows():\n",
    "        recovery_ranges[row['compound']] = {\n",
    "            'lower': row['lower_recovery_percent'],\n",
    "            'upper': row['upper_recovery_percent'],\n",
    "            'type': row['compound_type']\n",
    "        }\n",
    "    \n",
    "    # Get recovery columns from calculated data\n",
    "    recovery_columns = [col for col in calculated_recoveries_df.columns if col.endswith('_Recovery_%')]\n",
    "    \n",
    "    # Initialize results list\n",
    "    validation_results = []\n",
    "    \n",
    "    # Process each row in calculated recoveries\n",
    "    for idx, row in calculated_recoveries_df.iterrows():\n",
    "        sample_name = row.get('Name', f'Sample_{idx}')\n",
    "        sample_type = row.get('Type', 'Unknown')\n",
    "        \n",
    "        # Check each recovery column\n",
    "        for col in recovery_columns:\n",
    "            # Extract compound name from column (remove '_Recovery_%' suffix)\n",
    "            compound = col.replace('_Recovery_%', '')\n",
    "            \n",
    "            # Get calculated recovery value\n",
    "            calculated_recovery = row[col]\n",
    "            \n",
    "            # Skip if NaN\n",
    "            if pd.isna(calculated_recovery):\n",
    "                validation_results.append({\n",
    "                    'Sample_Name': sample_name,\n",
    "                    'Sample_Type': sample_type,\n",
    "                    'Compound': compound,\n",
    "                    'Calculated_Recovery_%': calculated_recovery,\n",
    "                    'Expected_Lower_%': np.nan,\n",
    "                    'Expected_Upper_%': np.nan,\n",
    "                    'Status': 'No Data',\n",
    "                    'Compound_Type': 'Unknown'\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # Check if compound exists in expected ranges\n",
    "            if compound in recovery_ranges:\n",
    "                lower_limit = recovery_ranges[compound]['lower']\n",
    "                upper_limit = recovery_ranges[compound]['upper']\n",
    "                compound_type = recovery_ranges[compound]['type']\n",
    "                \n",
    "                # Determine if recovery is within range\n",
    "                if lower_limit <= calculated_recovery <= upper_limit:\n",
    "                    status = 'Pass'\n",
    "                else:\n",
    "                    status = 'Fail'\n",
    "                \n",
    "                validation_results.append({\n",
    "                    'Sample_Name': sample_name,\n",
    "                    'Sample_Type': sample_type,\n",
    "                    'Compound': compound,\n",
    "                    'Calculated_Recovery_%': calculated_recovery,\n",
    "                    'Expected_Lower_%': lower_limit,\n",
    "                    'Expected_Upper_%': upper_limit,\n",
    "                    'Status': status,\n",
    "                    'Compound_Type': compound_type\n",
    "                })\n",
    "            else:\n",
    "                # Compound not found in expected ranges\n",
    "                validation_results.append({\n",
    "                    'Sample_Name': sample_name,\n",
    "                    'Sample_Type': sample_type,\n",
    "                    'Compound': compound,\n",
    "                    'Calculated_Recovery_%': calculated_recovery,\n",
    "                    'Expected_Lower_%': np.nan,\n",
    "                    'Expected_Upper_%': np.nan,\n",
    "                    'Status': 'No Reference',\n",
    "                    'Compound_Type': 'Unknown'\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(validation_results)\n",
    "\n",
    "def summarize_validation_results(validation_df):\n",
    "    \"\"\"\n",
    "    Create a summary of validation results.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    validation_df : pd.DataFrame\n",
    "        Output from validate_recoveries function\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Summary statistics of validation results\n",
    "    \"\"\"\n",
    "    \n",
    "    summary = {}\n",
    "    \n",
    "    # Overall statistics\n",
    "    total_measurements = len(validation_df)\n",
    "    passed = len(validation_df[validation_df['Status'] == 'Pass'])\n",
    "    failed = len(validation_df[validation_df['Status'] == 'Fail'])\n",
    "    no_data = len(validation_df[validation_df['Status'] == 'No Data'])\n",
    "    no_reference = len(validation_df[validation_df['Status'] == 'No Reference'])\n",
    "    \n",
    "    summary['Overall'] = {\n",
    "        'Total_Measurements': total_measurements,\n",
    "        'Passed': passed,\n",
    "        'Failed': failed,\n",
    "        'No_Data': no_data,\n",
    "        'No_Reference': no_reference,\n",
    "        'Pass_Rate_%': (passed / (passed + failed) * 100) if (passed + failed) > 0 else 0\n",
    "    }\n",
    "    \n",
    "    # By compound type\n",
    "    if 'Compound_Type' in validation_df.columns:\n",
    "        summary['By_Compound_Type'] = {}\n",
    "        for comp_type in validation_df['Compound_Type'].unique():\n",
    "            type_data = validation_df[validation_df['Compound_Type'] == comp_type]\n",
    "            type_passed = len(type_data[type_data['Status'] == 'Pass'])\n",
    "            type_failed = len(type_data[type_data['Status'] == 'Fail'])\n",
    "            \n",
    "            summary['By_Compound_Type'][comp_type] = {\n",
    "                'Passed': type_passed,\n",
    "                'Failed': type_failed,\n",
    "                'Pass_Rate_%': (type_passed / (type_passed + type_failed) * 100) if (type_passed + type_failed) > 0 else 0\n",
    "            }\n",
    "    \n",
    "    # By sample\n",
    "    summary['By_Sample'] = {}\n",
    "    for sample in validation_df['Sample_Name'].unique():\n",
    "        sample_data = validation_df[validation_df['Sample_Name'] == sample]\n",
    "        sample_passed = len(sample_data[sample_data['Status'] == 'Pass'])\n",
    "        sample_failed = len(sample_data[sample_data['Status'] == 'Fail'])\n",
    "        \n",
    "        summary['By_Sample'][sample] = {\n",
    "            'Passed': sample_passed,\n",
    "            'Failed': sample_failed,\n",
    "            'Pass_Rate_%': (sample_passed / (sample_passed + sample_failed) * 100) if (sample_passed + sample_failed) > 0 else 0\n",
    "        }\n",
    "    \n",
    "    return summary\n",
    "\n",
    "def mean_recoveries(calculated_recoveries_df, expected_recoveries_df):\n",
    "    \"\"\"\n",
    "    Calculate mean recoveries  recoveries across samples:\n",
    "    - Calculate mean recovery per compound\n",
    "    - Compare observed variability (RSD) with expected RSD\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    calculated_recoveries_df : pd.DataFrame\n",
    "        DataFrame containing calculated recoveries with columns like 'compound_Recovery_%'\n",
    "    expected_recoveries_df : pd.DataFrame\n",
    "        DataFrame with columns: 'compound', 'compound_type',\n",
    "        'lower_recovery_percent', 'upper_recovery_percent', 'rsd_percent'\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Summary results with mean recovery, observed RSD, expected RSD,\n",
    "        and pass/fail flags\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract recovery columns\n",
    "    recovery_columns = [col for col in calculated_recoveries_df.columns if col.endswith('_Recovery_%')]\n",
    "    \n",
    "    summary_results = []\n",
    "\n",
    "    for col in recovery_columns:\n",
    "        compound = col.replace('_Recovery_%', '')\n",
    "\n",
    "        values = calculated_recoveries_df[col].dropna()\n",
    "        if values.empty:\n",
    "            continue\n",
    "        \n",
    "        mean_recovery = values.mean()\n",
    "        observed_rsd = (values.std(ddof=1) / mean_recovery * 100) if mean_recovery != 0 else np.nan\n",
    "\n",
    "        # Lookup expected values\n",
    "        match = expected_recoveries_df[expected_recoveries_df['compound'] == compound]\n",
    "        if not match.empty:\n",
    "            lower = match['lower_recovery_percent'].values[0]\n",
    "            upper = match['upper_recovery_percent'].values[0]\n",
    "            expected_rsd = match['rsd_percent'].values[0] if 'rsd_percent' in match else np.nan\n",
    "            compound_type = match['compound_type'].values[0]\n",
    "            \n",
    "            # Flags\n",
    "            recovery_flag = \"Pass\" if lower <= mean_recovery <= upper else \"Fail\"\n",
    "            rsd_flag = \"Pass\" if (not np.isnan(expected_rsd) and not np.isnan(observed_rsd) \n",
    "                                  and observed_rsd <= expected_rsd) else \"Fail\"\n",
    "        else:\n",
    "            lower, upper, expected_rsd, compound_type = np.nan, np.nan, np.nan, \"Unknown\"\n",
    "            recovery_flag, rsd_flag = \"No Reference\", \"No Reference\"\n",
    "\n",
    "        summary_results.append({\n",
    "            \"Compound\": compound,\n",
    "            \"Compound_Type\": compound_type,\n",
    "            \"Mean_Recovery_%\": mean_recovery,\n",
    "            \"Expected_Lower_%\": lower,\n",
    "            \"Expected_Upper_%\": upper,\n",
    "            \"Recovery_Status\": recovery_flag,\n",
    "            \"Observed_RSD_%\": observed_rsd,\n",
    "            \"Expected_RSD_%\": expected_rsd,\n",
    "            \"RSD_Status\": rsd_flag\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(summary_results)\n",
    "\n",
    "\n",
    "\n",
    "def get_failed_recoveries(validation_df):\n",
    "    \"\"\"\n",
    "    Get only the failed recovery measurements for detailed review.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    validation_df : pd.DataFrame\n",
    "        Output from validate_recoveries function\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Only the failed measurements\n",
    "    \"\"\"\n",
    "    \n",
    "    failed_df = validation_df[validation_df['Status'] == 'Fail'].copy()\n",
    "    display(failed_df)\n",
    "    \n",
    "    \n",
    "    return failed_df\n",
    "\n",
    "\n",
    "def calculate_average_RRs_targets(rawdata, expected_concs_EIS, calibration_solutions, target_EIS_analogs=None):\n",
    "    \"\"\"\n",
    "    Calculate average response ratios for target compounds using either:\n",
    "    1. Direct isotope analogs (prefix-based, e.g., 13C8-PFOS -> PFOS), or\n",
    "    2. External Isotope Surrogates (EIS) from target_EIS_analogs dictionary.\n",
    "\n",
    "    Formula: RR = Area_target * Mass_IS / (Area_IS * Mass_target)\n",
    "    \"\"\"\n",
    "\n",
    "    # Define isotopic prefixes to remove for direct isotope analogs\n",
    "    isotope_prefixes = ['D7-', 'D9-', '13C4-', '13C3-', '13C5-', '13C2-', 'D3-', 'D5-', \n",
    "                        '13C8-', '13C9-', '13C6-', '13C7-']\n",
    "\n",
    "    target_EIS_pairs = {}\n",
    "\n",
    "    # --- Step 1: Build pairs from direct isotope analogs ---\n",
    "    for eis_compound in expected_concs_EIS.keys():\n",
    "        target_compound = None\n",
    "        for prefix in isotope_prefixes:\n",
    "            if eis_compound.startswith(prefix):\n",
    "                target_compound = eis_compound.replace(prefix, '', 1)\n",
    "                break\n",
    "\n",
    "        if target_compound:\n",
    "            if target_compound in calibration_solutions:\n",
    "                target_EIS_pairs[target_compound] = eis_compound\n",
    "\n",
    "    # --- Step 2: Add pairs from EIS analogs dict---\n",
    "    if target_EIS_analogs:\n",
    "        for target, eis in target_EIS_analogs.items():\n",
    "            if target not in target_EIS_pairs:  # don’t overwrite direct isotope matches\n",
    "                if target in calibration_solutions and eis in expected_concs_EIS:\n",
    "                    target_EIS_pairs[target] = eis\n",
    "\n",
    "    print(f\"Found {len(target_EIS_pairs)} total target-IS pairs:\")\n",
    "    for target, eis in target_EIS_pairs.items():\n",
    "        print(f\"  {target} -> {eis}\")\n",
    "    print()\n",
    "\n",
    "    # --- Step 3: Calibration and RR calculations ---\n",
    "    cal_data = rawdata[rawdata['Type'] == 'Cal'].copy()\n",
    "    results = []\n",
    "\n",
    "    for target_compound, eis_compound in target_EIS_pairs.items():\n",
    "        target_area_col = f\"{target_compound}_Area\"\n",
    "        eis_area_col = f\"{eis_compound}_Area\"\n",
    "\n",
    "        # Check if columns exist\n",
    "        if target_area_col not in cal_data.columns:\n",
    "            print(f\"Warning: Area column {target_area_col} not found in data\")\n",
    "            continue\n",
    "        if eis_area_col not in cal_data.columns:\n",
    "            print(f\"Warning: Area column {eis_area_col} not found in data\")\n",
    "            continue\n",
    "\n",
    "        if target_compound not in calibration_solutions:\n",
    "            print(f\"Warning: Target compound {target_compound} not found in calibration_solutions\")\n",
    "            continue\n",
    "        if eis_compound not in calibration_solutions:\n",
    "            print(f\"Warning: EIS compound {eis_compound} not found in calibration_solutions\")\n",
    "            continue\n",
    "\n",
    "        base_levels = ['L1','L2','L3','L4','L5','L6','L7']\n",
    "\n",
    "        # Check if L7 data is available\n",
    "        l7_available = True\n",
    "        l7_cal_data = cal_data[cal_data['Level'] == 'L7']\n",
    "        if l7_cal_data.empty:\n",
    "            l7_available = False\n",
    "        else:\n",
    "            mass_target_l7 = calibration_solutions[target_compound].get('L7', np.nan)\n",
    "            mass_eis_l7 = calibration_solutions[eis_compound].get('L7', np.nan)\n",
    "            if pd.isna(mass_target_l7) or pd.isna(mass_eis_l7):\n",
    "                l7_available = False\n",
    "            else:\n",
    "                target_areas_l7 = l7_cal_data[target_area_col].dropna()\n",
    "                eis_areas_l7 = l7_cal_data[eis_area_col].dropna()\n",
    "                if target_areas_l7.empty or eis_areas_l7.empty:\n",
    "                    l7_available = False\n",
    "\n",
    "        if l7_available:\n",
    "            levels_to_use = base_levels\n",
    "        else:\n",
    "            levels_to_use = base_levels[:-1]\n",
    "\n",
    "        response_ratios = []\n",
    "        level_data = []\n",
    "\n",
    "        for level in levels_to_use:\n",
    "            level_cal_data = cal_data[cal_data['Level'] == level]\n",
    "            if level_cal_data.empty:\n",
    "                print(f\"Warning: No data found for level {level}\")\n",
    "                continue\n",
    "\n",
    "            mass_target = calibration_solutions[target_compound].get(level, np.nan)\n",
    "            mass_eis = calibration_solutions[eis_compound].get(level, np.nan)\n",
    "            if pd.isna(mass_target) or pd.isna(mass_eis):\n",
    "                print(f\"Warning: Missing mass data for {target_compound} or {eis_compound} at level {level}\")\n",
    "                continue\n",
    "\n",
    "            target_areas = level_cal_data[target_area_col].dropna()\n",
    "            eis_areas = level_cal_data[eis_area_col].dropna()\n",
    "            if target_areas.empty or eis_areas.empty:\n",
    "                print(f\"Warning: No area values found for {target_compound} or {eis_compound} at level {level}\")\n",
    "                continue\n",
    "\n",
    "            area_target = target_areas.iloc[0] if len(target_areas) == 1 else target_areas.mean()\n",
    "            area_eis = eis_areas.iloc[0] if len(eis_areas) == 1 else eis_areas.mean()\n",
    "\n",
    "            if area_eis != 0 and mass_target != 0:\n",
    "                response_ratio = (area_target * mass_eis) / (area_eis * mass_target)\n",
    "                response_ratios.append(response_ratio)\n",
    "                level_data.append({\n",
    "                    'Level': level,\n",
    "                    'Area_Target': area_target,\n",
    "                    'Area_EIS': area_eis,\n",
    "                    'Mass_Target': mass_target,\n",
    "                    'Mass_EIS': mass_eis,\n",
    "                    'Response_Ratio': response_ratio\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Warning: Zero area or mass values for {target_compound}/{eis_compound} at level {level}\")\n",
    "\n",
    "        if response_ratios:\n",
    "            avg_response_ratio = np.mean(response_ratios)\n",
    "\n",
    "            rep_level = 'L4'\n",
    "            if target_compound in calibration_solutions and rep_level in calibration_solutions[target_compound]:\n",
    "                rep_mass_target = calibration_solutions[target_compound][rep_level]\n",
    "            else:\n",
    "                rep_mass_target = np.nan\n",
    "\n",
    "            if eis_compound in calibration_solutions and rep_level in calibration_solutions[eis_compound]:\n",
    "                rep_mass_eis = calibration_solutions[eis_compound][rep_level]\n",
    "            else:\n",
    "                rep_mass_eis = np.nan\n",
    "\n",
    "            results.append({\n",
    "                'Target_Compound': target_compound,\n",
    "                'EIS_Isotope': eis_compound,\n",
    "                'Mass_Target': rep_mass_target,\n",
    "                'Mass_EIS': rep_mass_eis,\n",
    "                'Area_Values_Target': [ld['Area_Target'] for ld in level_data],\n",
    "                'Area_Values_EIS': [ld['Area_EIS'] for ld in level_data],\n",
    "                'Response_Ratios': response_ratios,\n",
    "                'Average_Response_Ratio': avg_response_ratio,\n",
    "                'N_Levels': len(response_ratios),\n",
    "                'Levels_Used': [ld['Level'] for ld in level_data]\n",
    "            })\n",
    "        else:\n",
    "            print(f\"Warning: No valid response ratios calculated for {target_compound}\")\n",
    "\n",
    "    # --- Step 4: Build clean output DataFrame ---\n",
    "    if results:\n",
    "        output_df = pd.DataFrame([\n",
    "            {\n",
    "                'Target_Compound': r['Target_Compound'],\n",
    "                'EIS_Isotope': r['EIS_Isotope'],\n",
    "                'Mass_Target (L4)': r['Mass_Target'],\n",
    "                'Mass_EIS': r['Mass_EIS'],\n",
    "                'Average_Response_Ratio': r['Average_Response_Ratio'],\n",
    "                'RSD_%': (np.std(r['Response_Ratios']) / np.mean(r['Response_Ratios']) * 100)\n",
    "                        if len(r['Response_Ratios']) > 1 else np.nan,\n",
    "                'N_Levels': r['N_Levels'],\n",
    "                'Levels_Used': ', '.join(r['Levels_Used'])\n",
    "            }\n",
    "            for r in results\n",
    "        ])\n",
    "\n",
    "        output_df['Mass_Target (L4)'] = output_df['Mass_Target (L4)'].round(3)\n",
    "        output_df['Mass_EIS'] = output_df['Mass_EIS'].round(3)\n",
    "        output_df['Average_Response_Ratio'] = output_df['Average_Response_Ratio'].round(4)\n",
    "        output_df['RSD_%'] = output_df['RSD_%'].round(2)\n",
    "\n",
    "        from IPython.display import display\n",
    "        print(f\"\\nAVERAGE RESPONSE RATIOS FOR TARGET COMPOUNDS WITH ISOTOPES (n={len(output_df)})\")\n",
    "        display(output_df)\n",
    "        return output_df\n",
    "    else:\n",
    "        print(\"No valid results calculated\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def calculate_conc_targets(rawdata,\n",
    "                           RF_target_analytes,\n",
    "                           EIS_stock, dilution_EIS_stock, spiked_amount, Ws,\n",
    "                           Df, sampletype,\n",
    "                           debug_compound=None):\n",
    "    \"\"\"\n",
    "    Calculate concentrations for target analytes using EIS internal standards.\n",
    "\n",
    "    Formula:\n",
    "        Conc_target = (Area_target * M_EIS) / (Area_EIS * RF_target) * Df * (1 / Ws)\n",
    "    \"\"\"\n",
    "    # compute the spiked mass of each EIS\n",
    "    EIS_added = calc_mass_added_EIS(EIS_stock, dilution_EIS_stock, spiked_amount)\n",
    "\n",
    "    # Only process sample rows\n",
    "    sample_data = rawdata[rawdata['Type'] == sampletype].copy()\n",
    "\n",
    "    # Start output DataFrame\n",
    "    conc_data = sample_data[['Name', 'Type', 'Level']].copy()\n",
    "\n",
    "    # Loop over each target compound\n",
    "    for _, row in RF_target_analytes.iterrows():\n",
    "        target = row['Target_Compound']\n",
    "        eis_compound = row['EIS_Isotope']\n",
    "        rf_target = row['Average_Response_Ratio']\n",
    "\n",
    "        target_area_col = f\"{target}_Area\"\n",
    "        eis_area_col = f\"{eis_compound}_Area\"\n",
    "\n",
    "        # Check required columns\n",
    "        if target_area_col not in sample_data.columns or eis_area_col not in sample_data.columns:\n",
    "            print(f\"Warning: Missing area column(s) for {target} or {eis_compound}\")\n",
    "            continue\n",
    "\n",
    "        # Get spiked mass of EIS\n",
    "        if eis_compound not in EIS_added:\n",
    "            print(f\"Warning: No spiked mass found for EIS {eis_compound}\")\n",
    "            continue\n",
    "        m_eis = EIS_added[eis_compound]\n",
    "\n",
    "        # Compute concentrations\n",
    "        conc_values = (sample_data[target_area_col] * m_eis) / (\n",
    "                        sample_data[eis_area_col] * rf_target\n",
    "                      ) * Df * (1 / Ws)\n",
    "\n",
    "        conc_data[f\"{target}_Conc_Calc\"] = conc_values\n",
    "\n",
    "        # Debug printing\n",
    "        if debug_compound is not None and target == debug_compound:\n",
    "            print(f\"DEBUG for {target}:\")\n",
    "            print(f\"  Target area: {sample_data[target_area_col].values}\")\n",
    "            print(f\"  EIS area: {sample_data[eis_area_col].values}\")\n",
    "            print(f\"  Mass of EIS: {m_eis}\")\n",
    "            print(f\"  Response factor (RF): {rf_target}\")\n",
    "            print(f\"  Concentrations: {conc_values.values}\")\n",
    "\n",
    "    display(conc_data)\n",
    "\n",
    "    return conc_data\n",
    "\n",
    "def calculate_conc_EIS_cal(rawdata, EIS_RFS, dilution_NIS_stock_cal, Ws_cal,\n",
    "                           EIS_NIS_analogs, Df_cal, NIS_stock, spiked_amount_cal):\n",
    "    \"\"\"\n",
    "    Calculate concentrations for EIS compounds in calibration and QC data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rawdata : DataFrame\n",
    "        Input data with RR values and sample info (Type == \"Cal\" or \"QC\").\n",
    "    EIS_RFS : DataFrame\n",
    "        Contains Average_Response_Factor per compound.\n",
    "    dilution_NIS_stock_cal : float\n",
    "        Dilution factor for NIS stock.\n",
    "    Ws_cal : float\n",
    "        Calibration volume [L].\n",
    "    EIS_NIS_analogs : dict\n",
    "        Mapping from EIS compound -> NIS analog.\n",
    "    Df_cal : float\n",
    "        Dilution factor for calibration samples.\n",
    "    NIS_stock : dict\n",
    "        NIS stock concentrations (ng/mL).\n",
    "    spiked_amount_cal : float\n",
    "        Spiked amount for calibration [ng].\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    tuple of DataFrames\n",
    "        (conc_cal, conc_QC) - Separate DataFrames for calibration and QC data.\n",
    "        Returns (None, None) if no data found for either type.\n",
    "    \"\"\"\n",
    "    # Compute the amount of added NIS per analog \n",
    "    NIS_added = calc_mass_added_NIS(NIS_stock, dilution_NIS_stock_cal, spiked_amount_cal)\n",
    "    \n",
    "    # Filter data for Cal and QC types\n",
    "    cal_data = rawdata[rawdata['Type'] == 'Cal'].copy()\n",
    "    qc_data = rawdata[rawdata['Type'] == 'QC'].copy()\n",
    "    \n",
    "    # Initialize result DataFrames\n",
    "    conc_cal = None\n",
    "    conc_QC = None\n",
    "    \n",
    "    # Get EIS compounds\n",
    "    eis_compounds = set(EIS_NIS_analogs.keys())\n",
    "    \n",
    "    # Process Calibration data\n",
    "    if not cal_data.empty:\n",
    "        conc_cal = cal_data[['Name', 'Type', 'Level']].copy()\n",
    "        \n",
    "        for eis_compound in eis_compounds:\n",
    "            nis_compound = EIS_NIS_analogs[eis_compound]\n",
    "            rr_column = f\"{eis_compound}_RR\"\n",
    "            \n",
    "            if rr_column not in cal_data.columns:\n",
    "                print(f\"Warning: RR column {rr_column} not found in Cal data\")\n",
    "                continue\n",
    "                \n",
    "            avg_rf_row = EIS_RFS[EIS_RFS[\"Compound_Name\"] == eis_compound]\n",
    "            if avg_rf_row.empty:\n",
    "                print(f\"Warning: No RF found for {eis_compound}\")\n",
    "                continue\n",
    "                \n",
    "            avg_rf = avg_rf_row[\"Average_Response_Factor\"].values[0]\n",
    "            \n",
    "            if nis_compound not in NIS_added:\n",
    "                print(f\"Warning: No NIS mass found for analog {nis_compound}\")\n",
    "                continue\n",
    "                \n",
    "            m_nis = NIS_added[nis_compound]\n",
    "            \n",
    "            # Concentration formula for calibration\n",
    "            conc_values = (cal_data[rr_column] * m_nis / avg_rf) * Df_cal * (1 / Ws_cal)\n",
    "            conc_cal[f\"{eis_compound}_Conc_Calc\"] = conc_values\n",
    "    \n",
    "    # Process QC data\n",
    "    if not qc_data.empty:\n",
    "        conc_QC = qc_data[['Name', 'Type', 'Level']].copy()\n",
    "        \n",
    "        for eis_compound in eis_compounds:\n",
    "            nis_compound = EIS_NIS_analogs[eis_compound]\n",
    "            rr_column = f\"{eis_compound}_RR\"\n",
    "            \n",
    "            if rr_column not in qc_data.columns:\n",
    "                print(f\"Warning: RR column {rr_column} not found in QC data\")\n",
    "                continue\n",
    "                \n",
    "            avg_rf_row = EIS_RFS[EIS_RFS[\"Compound_Name\"] == eis_compound]\n",
    "            if avg_rf_row.empty:\n",
    "                print(f\"Warning: No RF found for {eis_compound}\")\n",
    "                continue\n",
    "                \n",
    "            avg_rf = avg_rf_row[\"Average_Response_Factor\"].values[0]\n",
    "            \n",
    "            if nis_compound not in NIS_added:\n",
    "                print(f\"Warning: No NIS mass found for analog {nis_compound}\")\n",
    "                continue\n",
    "                \n",
    "            m_nis = NIS_added[nis_compound]\n",
    "            \n",
    "            # Concentration formula for QC (same as calibration)\n",
    "            conc_values = (qc_data[rr_column] * m_nis / avg_rf) * Df_cal * (1 / Ws_cal)\n",
    "            conc_QC[f\"{eis_compound}_Conc_Calc\"] = conc_values\n",
    "    \n",
    "    # Display results\n",
    "    if conc_cal is not None:\n",
    "        print(\"Calibration Data:\")\n",
    "        display(conc_cal)\n",
    "    \n",
    "    if conc_QC is not None:\n",
    "        print(\"QC Data:\")\n",
    "        display(conc_QC)\n",
    "    \n",
    "    return conc_cal, conc_QC\n",
    "\n",
    "\n",
    "def calculate_eis_rse_modified(df, expected_concentrations, p=2, exclude_levels=None):\n",
    "    \"\"\"\n",
    "    Calculate RSE for EIS compounds using the new dataframe structure.\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame with columns ending in '_Conc_Calc'\n",
    "    expected_concentrations: dict with expected concentrations for each compound\n",
    "    p: power parameter for RSE calculation (default=2)\n",
    "    exclude_levels: list of calibration levels to exclude (e.g., ['L1', 'L7'] or ['L3'])\n",
    "    \n",
    "    Returns:\n",
    "    dict: RSE results for each EIS compound\n",
    "    \"\"\"\n",
    "    # Handle exclude_levels parameter\n",
    "    if exclude_levels is None:\n",
    "        exclude_levels = []\n",
    "    elif isinstance(exclude_levels, str):\n",
    "        exclude_levels = [exclude_levels]  # Convert single string to list\n",
    "    \n",
    "    # Find EIS compounds by looking for columns ending with '_Conc_Calc'\n",
    "    eis_compounds = []\n",
    "    for col in df.columns:\n",
    "        if '_Conc_Calc' in col:\n",
    "            compound_name = col.replace('_Conc_Calc', '')\n",
    "            # Check if it's an EIS compound (starts with isotope labels)\n",
    "            if any(compound_name.startswith(prefix) for prefix in ['13C', '18O', '15N', '2H', 'D']):\n",
    "                eis_compounds.append(compound_name)\n",
    "                \n",
    "    # Check if EIS compounds list length matches expected concentrations\n",
    "    eis_in_expected = [compound for compound in eis_compounds if compound in expected_concentrations]\n",
    "    print(f\"EIS compounds found: {len(eis_compounds)}\")\n",
    "    print(f\"EIS compounds with expected concentrations: {len(eis_in_expected)}\")\n",
    "    \n",
    "    if len(eis_compounds) != len(eis_in_expected):\n",
    "        missing_compounds = [compound for compound in eis_compounds if compound not in expected_concentrations]\n",
    "        print(f\"Warning: Missing expected concentrations for EIS compounds: {missing_compounds}\")\n",
    "    \n",
    "    # Filter for Cal samples\n",
    "    cal_data = df[df['Type'] == 'Cal'].copy()\n",
    "    if cal_data.empty:\n",
    "        print(\"No CAL samples found in the data\")\n",
    "        return {}\n",
    "    \n",
    "    # Exclude specified calibration levels\n",
    "    if exclude_levels:\n",
    "        print(f\"Excluding calibration levels: {exclude_levels}\")\n",
    "        original_count = len(cal_data)\n",
    "        cal_data = cal_data[~cal_data['Level'].isin(exclude_levels)]\n",
    "        excluded_count = original_count - len(cal_data)\n",
    "        print(f\"Excluded {excluded_count} samples from levels {exclude_levels}\")\n",
    "        \n",
    "        if cal_data.empty:\n",
    "            print(\"Warning: No CAL samples remaining after excluding specified levels\")\n",
    "            return {}\n",
    "    \n",
    "    print(f\"Number of Cal samples used for analysis: {len(cal_data)}\")\n",
    "    \n",
    "    # Show which levels are being used\n",
    "    if 'Level' in cal_data.columns:\n",
    "        used_levels = sorted(cal_data['Level'].unique())\n",
    "        print(f\"Calibration levels used: {used_levels}\")\n",
    "    \n",
    "    rse_results_eis = {}\n",
    "    for compound in eis_compounds:\n",
    "        conc_col = f\"{compound}_Conc_Calc\"\n",
    "        \n",
    "        if conc_col not in df.columns:\n",
    "            print(f\"Warning: Column {conc_col} not found\")\n",
    "            continue\n",
    "            \n",
    "        if compound not in expected_concentrations:\n",
    "            print(f\"Warning: No expected concentrations provided for {compound}\")\n",
    "            continue\n",
    "        \n",
    "        # Get actual concentrations from filtered Cal samples\n",
    "        actual_concs = cal_data[conc_col].values\n",
    "        expected_conc = expected_concentrations[compound]\n",
    "        \n",
    "        # Filter out NaN values\n",
    "        valid_mask = ~np.isnan(actual_concs)\n",
    "        actual_concs_clean = actual_concs[valid_mask]\n",
    "        \n",
    "        if len(actual_concs_clean) == 0:\n",
    "            print(f\"Warning: No valid data points for {compound}\")\n",
    "            continue\n",
    "        \n",
    "        # Create list of expected concentrations (same value repeated)\n",
    "        expected_concs_list = [expected_conc] * len(actual_concs_clean)\n",
    "        \n",
    "        # Calculate RSE\n",
    "        rse_result = calculate_rse(expected_concs_list, actual_concs_clean.tolist(), compound, p)\n",
    "        rse_results_eis[compound] = rse_result\n",
    "        \n",
    "        # Print compound-specific info if excluding levels\n",
    "        if exclude_levels:\n",
    "            print(f\"{compound}: Using {len(actual_concs_clean)} data points for RSE calculation\")\n",
    "    \n",
    "    return rse_results_eis\n",
    "\n",
    "def filter_expected_concs_by_level(expected_concs_dict, level):\n",
    "    \"\"\"Filter expected concentrations dictionary to only contain specified level.\"\"\"\n",
    "    return {compound: [conc_list[level - 1]] for compound, conc_list in expected_concs_dict.items()}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
